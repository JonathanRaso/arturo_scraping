{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scraping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMDb top 250 films scraping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def imdb_film_pages_urls():\n",
    "    # fetching film pages' urls\n",
    "    pages_urls = []\n",
    "\n",
    "    page_start = 1\n",
    "    while page_start <= 250:\n",
    "        url = f'https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start={page_start}&ref_=adv_nxt'\n",
    "        pages_urls.append(url)\n",
    "        page_start = page_start + 50\n",
    "\n",
    "    return pages_urls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "imdb_urls = imdb_film_pages_urls()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def imdb_films_content(pages_urls):\n",
    "    # parsing html content from request response\n",
    "    pages_content = []\n",
    "\n",
    "    # fetch requests in US format\n",
    "    headers = {\"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "\n",
    "    for page in pages_urls:\n",
    "        response = rq.get(page, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error fetching page\")\n",
    "        else:\n",
    "            pages_content.append(response.content)\n",
    "\n",
    "    return pages_content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "imdb_pages_content = imdb_films_content(imdb_urls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def imdb_film_df(pages_content):\n",
    "    # collect film needed information\n",
    "    film_infos = []\n",
    "\n",
    "    for content in pages_content:\n",
    "        soup = bs(content, \"html.parser\")\n",
    "        for film_content in soup.find_all(\"div\", class_=\"lister-item mode-advanced\"):\n",
    "            film_infos.append(film_content)\n",
    "\n",
    "    # list with fetched data\n",
    "    film_data = []\n",
    "\n",
    "    # fetch film info from html hashes\n",
    "    for info in film_infos:\n",
    "        title = (info.find(\"h3\", class_=\"lister-item-header\").findChildren()[1]).get_text(strip=True)\n",
    "        year = (info.h3.findChildren()[2]).get_text(strip=True)[1:5]\n",
    "        runtime = (info.find(\"p\", class_=\"text-muted\").findChildren()[2]).get_text(strip=True)[0:3]\n",
    "        genre = (info.find(\"p\", class_=\"text-muted\").find(\"span\", class_=\"genre\")).get_text(strip=True)\n",
    "        certificate = info.find(\"span\", class_ =\"certificate\").get_text(strip=True)\n",
    "        rating = (info.find(\"div\", class_=\"ratings-bar\").find(\"div\", class_='inline-block ratings-imdb-rating').findChildren()[1]).get_text(strip=True)\n",
    "        director = info.find_all('p', class_=\"\")[0].a.text.strip()\n",
    "\n",
    "        # define list to fill in all fetched data\n",
    "        film_data.append([title, year, runtime, genre, certificate, rating, director])\n",
    "\n",
    "        # define dataframe containing top 250 films data\n",
    "        top250_film = pd.DataFrame(film_data, columns = ['title', 'year', 'runtime', 'genre', 'certificate', 'rating', 'director'])\n",
    "\n",
    "    return top250_film\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "topfilm = imdb_film_df(imdb_pages_content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rotten Tomatoes tomatometer and audience score scraping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def rotten_scores_fetch(film_df):\n",
    "    # define empty list\n",
    "    score_data = []\n",
    "\n",
    "    # define header language for getting data in english\n",
    "    headers = {\"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "\n",
    "    # define static part of the url\n",
    "    uri = 'https://www.rottentomatoes.com/m/'\n",
    "\n",
    "    # loop through titles in the dataframe\n",
    "    for title in film_df['title']:\n",
    "        changed_title = title.replace(\" \", \"_\").replace(\"The_\", \"\").replace(\":\", \"\").replace(\".\", \"\").replace(\"'\", \"\").replace(\"-\", \"\").replace(\",\", \"\").replace(\"Ã¤\", \"\").replace(\"__\",\"_\")\n",
    "        url = f'{uri}{changed_title}'\n",
    "        data = rq.get(url, headers=headers)\n",
    "\n",
    "        if data.status_code == 404:\n",
    "            score_list = ['not found', 'not_found']\n",
    "            score_data.append(score_list)\n",
    "\n",
    "        else:\n",
    "            soup = bs(data.text, 'html.parser')\n",
    "\n",
    "            audience_score = soup.find(\"score-board\")[\"audiencescore\"]\n",
    "            tomato_score = soup.find(\"score-board\")[\"tomatometerscore\"]\n",
    "\n",
    "            score_list = [tomato_score, audience_score]\n",
    "\n",
    "            score_data.append(score_list)\n",
    "\n",
    "    return score_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rotten_scores = rotten_scores_fetch(topfilm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def final_df(score_data, imdb_dataframe):\n",
    "    # define data folder containing csv\n",
    "    dir_name = '../data'\n",
    "\n",
    "    # Store imdb_dataframe in final_df\n",
    "    final_df = imdb_dataframe\n",
    "\n",
    "    # Create score_df with score_data from previous function\n",
    "    score_df = pd.DataFrame(score_data, columns = ['tomato_meter','audience_score'])\n",
    "\n",
    "    # Create new columns in our final dataframe\n",
    "    final_df['tomato_meter'] = score_df['tomato_meter']\n",
    "    final_df['audience_score'] = score_df['audience_score']\n",
    "\n",
    "    # Check if dir_name already exists before creating csv file\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        print(\"Directory \" , dir_name ,  \" Created \")\n",
    "    else:\n",
    "        print(\"Directory \" , dir_name ,  \" already exists\")\n",
    "\n",
    "    # Export the dataframe with to_csv()\n",
    "    final_df.to_csv(f'{dir_name}/top_250_films.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    return final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topfilm_rotten = final_df(rotten_scores, topfilm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}